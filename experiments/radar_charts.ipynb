{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_directory = os.getcwd()\n",
    "if not os.path.exists(current_directory + '\\\\experimental_data'):\n",
    "    os.makedirs(current_directory + '\\\\experimental_data')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\plots')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\results')\n",
    "sys.path.append(current_directory.replace('experiments', ''))\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.set_loglevel('WARNING')\n",
    "from run import execute_simulation, create_experiment_snapshots, execute_ai_model, single_mtd_simulation, single_mtd_ai_simulation\n",
    "from mtdnetwork.mtd.completetopologyshuffle import CompleteTopologyShuffle\n",
    "from mtdnetwork.mtd.ipshuffle import IPShuffle\n",
    "from mtdnetwork.mtd.hosttopologyshuffle import HostTopologyShuffle\n",
    "from mtdnetwork.mtd.portshuffle import PortShuffle\n",
    "from mtdnetwork.mtd.osdiversity import OSDiversity\n",
    "from mtdnetwork.mtd.servicediversity import ServiceDiversity\n",
    "from mtdnetwork.mtd.usershuffle import UserShuffle\n",
    "from mtdnetwork.mtd.osdiversityassignment import OSDiversityAssignment\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment_snapshots([25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters\n",
    "epsilon = 1.0  # exploration rate\n",
    "\n",
    "# Simulator Settings\n",
    "start_time = 0\n",
    "finish_time = 3000\n",
    "mtd_interval = 100\n",
    "total_nodes = 300\n",
    "new_network = True\n",
    "features = [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\",  \"overall_asr_avg\", \"roa\", \"shortest_path_variability\", \"risk\"]\n",
    "model = \"main_network_final_host_compromise_ratio#exposed_endpoints#attack_path_exposure#overall_asr_avg#roa#shortest_path_variability#risk\"\n",
    "trial = 2\n",
    "\n",
    "mtd_strategies = [\n",
    "    None,\n",
    "    CompleteTopologyShuffle,\n",
    "    # HostTopologyShuffle,\n",
    "    IPShuffle,\n",
    "    OSDiversity,\n",
    "    # PortShuffle,\n",
    "    # OSDiversityAssignment,\n",
    "    ServiceDiversity,\n",
    "    # UserShuffle\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomtd = single_mtd_simulation(\"nomtd\", [None], checkpoint=list(np.arange(0.01, 1.01, 0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(nomtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nomtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtd_ai = single_mtd_ai_simulation('mtd_ai', model, start_time, finish_time, total_nodes, new_network = new_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(mtd_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mtd_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RadarPlot:\n",
    "    def __init__(self, epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial):\n",
    "        # Learning Parameters\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "\n",
    "        # Simulator Settings\n",
    "        self.start_time = start_time\n",
    "        self.finish_time = finish_time\n",
    "        self.mtd_interval = mtd_interval\n",
    "        self.schemes = [ 'mtd_ai', 'simultaneous', 'random', 'alternative']\n",
    "        self.total_nodes = total_nodes\n",
    "        self.new_network = new_network\n",
    "        self.features = features\n",
    "        self.model = model\n",
    "        self.trial = trial\n",
    "        self.normalization_values = self.get_scheme_values('nomtd')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_scheme_values(self, scheme):\n",
    "        # Simulate and stack nomtd DataFrames\n",
    "        dfs = []\n",
    "        for _ in range(self.trial):\n",
    "            if scheme == 'nomtd':\n",
    "                mtd = pd.DataFrame(single_mtd_simulation(scheme, [None], checkpoint=list(np.arange(0.01, 1.01, 0.01)))).drop('Name', axis=1)\n",
    "            else:\n",
    "                mtd = pd.DataFrame(single_mtd_ai_simulation('mtd_ai', model, start_time, finish_time, total_nodes, new_network = new_network)).drop('Name', axis=1)\n",
    "            dfs.append(mtd)\n",
    "        stacked_nomtd = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # Calculate median for normalization\n",
    "        median_df = stacked_nomtd.groupby(['mtd_interval', 'network_size']).median()\n",
    "\n",
    "        # Filter the DataFrame for mtd_interval = 100 and network_size = 25\n",
    "        normalization_values = median_df.loc[(100, 25)].to_dict()\n",
    "\n",
    "        return normalization_values\n",
    "\n",
    "    def scale_metrics(self, metrics_dict, normalization_dict):\n",
    "        # Define which metrics should be maximized and which should be minimized\n",
    "        metrics_to_maximize = {'ASR', 'ROA', 'exposed_endpoints'}  \n",
    "        metrics_to_minimize = {'host_compromise_ratio', 'time_to_compromise', 'attack_path_exposure'}  \n",
    "\n",
    "        scaled_metrics = {}\n",
    "\n",
    "        for key, value in metrics_dict.items():\n",
    "            if key in normalization_dict:\n",
    "                norm_value = normalization_dict[key]\n",
    "\n",
    "                if norm_value != 0:\n",
    "                    if key in metrics_to_maximize:\n",
    "                        # Normalize by dividing the metric value by the normalization value\n",
    "                        scaled_metrics[key] = value / norm_value\n",
    "                    elif key in metrics_to_minimize:\n",
    "                        # Inverse the ratio for metrics to be minimized\n",
    "                        scaled_metrics[key] = 1 / (value / norm_value)\n",
    "                    else:\n",
    "                        # Handle cases where the metric is not in either category\n",
    "                        scaled_metrics[key] = value / norm_value\n",
    "                else:\n",
    "                    # Handle the case where norm_value is zero\n",
    "                    scaled_metrics[key] = 1  # Or any other placeholder value as needed\n",
    "            else:\n",
    "                # Handle cases where normalization value is not defined\n",
    "                scaled_metrics[key] = value  # Or handle differently as needed\n",
    "\n",
    "        return scaled_metrics\n",
    "\n",
    "\n",
    "    def plot_single_radar(self, metrics_values, scheme, std_dev_values=None):\n",
    "        labels = list(metrics_values.keys())\n",
    "        values = list(metrics_values.values())\n",
    "        num_vars = len(labels)\n",
    "\n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        values += values[:1]\n",
    "        if std_dev_values:\n",
    "            std_dev_values = list(std_dev_values.values())  # Assuming std_dev_values is also a dictionary\n",
    "            std_dev_values += std_dev_values[:1]\n",
    "        labels += labels[:1]  # Close the circle by repeating the first label\n",
    "\n",
    "        # Create radar plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Plot data\n",
    "        ax.fill(angles, values, color='blue', alpha=0.25)\n",
    "        ax.plot(angles, values, color='blue', linewidth=2, label=scheme)\n",
    "\n",
    "        # Add error bars if provided\n",
    "        if std_dev_values:\n",
    "            for i in range(num_vars):\n",
    "                angle = angles[i]\n",
    "                value = values[i]\n",
    "                error = std_dev_values[i]\n",
    "                ax.errorbar(angle, value, yerr=error, fmt='o', color='blue', capsize=5, elinewidth=2)\n",
    "\n",
    "        # Add score labels\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = values[i]\n",
    "            ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        # Labels\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])  # Set ticks without the last angle\n",
    "        ax.set_xticklabels(labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_comparison_radar(self, baseline_metrics):\n",
    "        \"\"\"\n",
    "        Plot a radar chart comparing multiple schemes to a baseline.\n",
    "\n",
    "        :param baseline_metrics: Dictionary of metrics for the baseline (e.g., no MTD).\n",
    "        :param schemes_metrics: Dictionary where keys are scheme names and values are dictionaries of metrics.\n",
    "        \"\"\"\n",
    "        # Convert baseline metrics to the format expected by the plot function\n",
    "        baseline_labels = list(baseline_metrics.keys())\n",
    "        baseline_values = list(baseline_metrics.values())\n",
    "        num_vars = len(baseline_labels)\n",
    "\n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        baseline_values += baseline_values[:1]\n",
    "        \n",
    "\n",
    "        # Create a dictionary to store metrics for each scheme\n",
    "        schemes_metrics = {}\n",
    "        \n",
    "        for scheme in self.schemes:\n",
    "            if scheme == 'mtd_ai':\n",
    "                metrics_values = single_mtd_ai_simulation('mtd_ai', model, start_time, finish_time, total_nodes, new_network = new_network)\n",
    "            # Here you would normally call a function to get metrics for the scheme.\n",
    "            # For demonstration, I'll use placeholder values.\n",
    "            # Replace the following line with your actual metric retrieval.\n",
    "            else:\n",
    "                metrics_values = self.get_scheme_values(scheme)\n",
    "            metrics_values = self.scale_metrics(metrics_dict=metrics_values, normalization_dict=self.normalization_values)\n",
    "            \n",
    "            # Store metrics values in the dictionary\n",
    "            schemes_metrics[scheme] = metrics_values\n",
    "\n",
    "\n",
    "        # Create radar plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "        \n",
    "        # Plot baseline\n",
    "        ax.fill(angles, baseline_values, color='grey', alpha=0.25, label='Baseline (No MTD)')\n",
    "        ax.plot(angles, baseline_values, color='grey', linewidth=2, linestyle='--')\n",
    "\n",
    "        # Plot each scheme\n",
    "        colors = ['blue', 'green', 'red', 'orange']  # Define colors for each scheme\n",
    "        for i, (scheme, metrics_values) in enumerate(schemes_metrics.items()):\n",
    "            values = list(metrics_values.values())\n",
    "            values += values[:1]  # Close the circle\n",
    "            ax.fill(angles, values, color=colors[i % len(colors)], alpha=0.25, label=scheme)\n",
    "            ax.plot(angles, values, color=colors[i % len(colors)], linewidth=2)\n",
    "\n",
    "        # Add score labels\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = baseline_values[i]\n",
    "            ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        # Labels\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(baseline_labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.title(f\"Comparison Radar Chart Against Baseline\", size=15, color='black', y=1.1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"main_network_all_features\"\n",
    "# features = [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\",  \"overall_asr_avg\", \"roa\", \"shortest_path_variability\", \"risk\"]\n",
    "# for feature in features:\n",
    "#     model = \"main_network_\" + feature\n",
    "#     radar = RadarPlot(epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial=trial)\n",
    "#     # Plot against all schemes\n",
    "#     radar.plot_against_all_schemes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoMTD\n",
      "NoMTD\n"
     ]
    }
   ],
   "source": [
    "radar = RadarPlot(epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial=trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = ['MEF', 'ASR', 'time_to_compromise', 'host_compromise_ratio', 'exposed_endpoints', 'attack_path_exposure', 'ROA', 'risk', 'shortest_path_variability']\n",
    "scheme_result = radar.get_scheme_values('mtd_ai')\n",
    "scaled_metrics = radar.scale_metrics(scheme_result,radar.normalization_values)\n",
    "# Assuming no standard deviation values for this example\n",
    "radar.plot_single_radar(scheme='mtd_ai',metrics_values=scaled_metrics)\n",
    "# radar.plot_comparison_radar(radar.normalization_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEF': 1,\n",
       " 'ASR': 0.21096491228070174,\n",
       " 'time_to_compromise': 0.772915047910984,\n",
       " 'host_compromise_ratio': 27.0,\n",
       " 'exposed_endpoints': 1.0,\n",
       " 'attack_path_exposure': 3.4598403841451195,\n",
       " 'ROA': 0.09894108056183537,\n",
       " 'risk': 0.08135674913250922,\n",
       " 'shortest_path_variability': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_directory = os.getcwd()\n",
    "if not os.path.exists(current_directory + '\\\\experimental_data'):\n",
    "    os.makedirs(current_directory + '\\\\experimental_data')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\plots')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\results')\n",
    "sys.path.append(current_directory.replace('experiments', ''))\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.set_loglevel('WARNING')\n",
    "from run import execute_simulation, create_experiment_snapshots, execute_ai_model\n",
    "from mtdnetwork.mtd.completetopologyshuffle import CompleteTopologyShuffle\n",
    "from mtdnetwork.mtd.ipshuffle import IPShuffle\n",
    "from mtdnetwork.mtd.hosttopologyshuffle import HostTopologyShuffle\n",
    "from mtdnetwork.mtd.portshuffle import PortShuffle\n",
    "from mtdnetwork.mtd.osdiversity import OSDiversity\n",
    "from mtdnetwork.mtd.servicediversity import ServiceDiversity\n",
    "from mtdnetwork.mtd.usershuffle import UserShuffle\n",
    "from mtdnetwork.mtd.osdiversityassignment import OSDiversityAssignment\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment_snapshots([25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters\n",
    "epsilon = 1.0  # exploration rate\n",
    "\n",
    "# Simulator Settings\n",
    "start_time = 0\n",
    "finish_time = 3000\n",
    "mtd_interval = 100\n",
    "total_nodes = 300\n",
    "new_network = True\n",
    "features = [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\",  \"overall_asr_avg\", \"roa\", \"shortest_path_variability\", \"risk\"]\n",
    "model = \"main_network_final_host_compromise_ratio#exposed_endpoints#attack_path_exposure#overall_asr_avg#roa#shortest_path_variability#risk\"\n",
    "trial = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RadarPlot:\n",
    "    def __init__(self, epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial):\n",
    "        # Learning Parameters\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "\n",
    "        # Simulator Settings\n",
    "        self.start_time = start_time\n",
    "        self.finish_time = finish_time\n",
    "        self.mtd_interval = mtd_interval\n",
    "        self.schemes = [ 'mtd_ai', 'simultaneous', 'random', 'alternative']\n",
    "        self.total_nodes = total_nodes\n",
    "        self.new_network = new_network\n",
    "        self.features = features\n",
    "        self.model = model\n",
    "        self.trial = trial\n",
    "        self.normalization_values = self.calculate_normalized_values()\n",
    "        print(self.normalization_values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_normalized_values(self):\n",
    "        # DataFrame to store the results of each trial\n",
    "        security_metrics = pd.DataFrame(columns=self.features)\n",
    "\n",
    "        for _ in range(self.trial):\n",
    "            # Execute the simulation and collect the results\n",
    "            evaluation = execute_simulation(\n",
    "                features=features,\n",
    "                start_time=self.start_time,\n",
    "                finish_time=self.finish_time,\n",
    "                scheme=\"None\",\n",
    "                mtd_interval=self.mtd_interval,\n",
    "                total_nodes=self.total_nodes,\n",
    "                new_network=self.new_network\n",
    "            )\n",
    "            print(evaluation.security_metrics_record.get_record())\n",
    "            # Extract the latest security metrics record from the simulation\n",
    "            security_metrics_trial = evaluation.security_metrics_record.get_record().iloc[-1]\n",
    "            security_metrics = pd.concat([security_metrics, pd.DataFrame([security_metrics_trial])], ignore_index=True)\n",
    "\n",
    "        # Calculate median for normalization\n",
    "        normalized_values = security_metrics.median().to_dict()\n",
    "\n",
    "        return normalized_values\n",
    "\n",
    "    \n",
    "    def compute_metrics(self, scheme,normalization_values=None):\n",
    "            # DataFrame to store the results of each trial\n",
    "            security_metrics = pd.DataFrame(columns=self.features)\n",
    "\n",
    "            for _ in range(self.trial):\n",
    "                # Execute the AI model and collect the results\n",
    "                evaluation = execute_ai_model(\n",
    "                    model=self.model,\n",
    "                    features=self.features,\n",
    "                    start_time=self.start_time,\n",
    "                    finish_time=self.finish_time,\n",
    "                    mtd_interval=self.mtd_interval,\n",
    "                    scheme= scheme,\n",
    "                    total_nodes=self.total_nodes,\n",
    "                    new_network=self.new_network\n",
    "                )\n",
    "\n",
    "                # Extract the latest security metrics record\n",
    "                security_metrics_trial = evaluation.security_metrics_record.get_record().drop('times', axis=1).iloc[-1]\n",
    "                security_metrics = pd.concat([security_metrics, pd.DataFrame([security_metrics_trial])], ignore_index=True)\n",
    "\n",
    "            # Normalize each column if normalization values are provided\n",
    "            if normalization_values:\n",
    "                for column, norm_value in normalization_values.items():\n",
    "                    if column in security_metrics.columns:\n",
    "                        if norm_value != 0:  # Check if norm_value is not zero to avoid division by zero\n",
    "                            if column in [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\", \"risk\"]:\n",
    "                                security_metrics[column] = 1 / (security_metrics[column] / norm_value)\n",
    "                            else:\n",
    "                                security_metrics[column] = security_metrics[column] / norm_value\n",
    "                        else:\n",
    "                            # Handle the case where norm_value is zero\n",
    "                            # You can either set the result to NaN, zero, or any other placeholder value\n",
    "                            security_metrics[column] = 1  \n",
    "\n",
    "            # Calculate median and standard deviation for each metric\n",
    "            results = {\n",
    "                'Median': security_metrics.median(),\n",
    "                'Standard Deviation': security_metrics.std()\n",
    "            }\n",
    "\n",
    "            # Convert results to a DataFrame\n",
    "            results_security_metrics = pd.DataFrame(results).dropna()\n",
    "\n",
    "            # Extract data for the radar plot\n",
    "            metrics_values = results_security_metrics['Median'].tolist()\n",
    "            labels = results_security_metrics.index.tolist()\n",
    "\n",
    "            return labels, metrics_values, results_security_metrics['Standard Deviation'].tolist()\n",
    "    \n",
    "\n",
    "    def plot_radar(self, labels, metrics_values, std_dev_values, scheme):\n",
    "        # Number of metrics\n",
    "        num_vars = len(labels)\n",
    "\n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        metrics_values += metrics_values[:1]\n",
    "        std_dev_values += std_dev_values[:1]\n",
    "        labels += labels[:1]  # Close the circle by repeating the first label\n",
    "\n",
    "        # Create radar plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Plot data\n",
    "        ax.fill(angles, metrics_values, color='blue', alpha=0.25)\n",
    "        ax.plot(angles, metrics_values, color='blue', linewidth=2, label='Median')\n",
    "\n",
    "        # Add error bars\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = metrics_values[i]\n",
    "            error = std_dev_values[i]\n",
    "            ax.errorbar(angle, value, yerr=error, fmt='o', color='blue', capsize=5, elinewidth=2)\n",
    "\n",
    "        # Add score labels\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = metrics_values[i]\n",
    "            ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        # Labels\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])  # Set ticks without the last angle\n",
    "        ax.set_xticklabels(labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.title(f\"Radar chart with AI with all 4 single MTD (compare to {scheme}) over {self.trial} trials\", size=15, color='blue', y=1.1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_stacked_radar(self, metrics_data, scheme_names):\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Define colors for each scheme\n",
    "        colors = ['blue', 'green', 'red', 'orange', 'purple', 'cyan']\n",
    "\n",
    "        for i, (labels, metrics_values, std_dev_values) in enumerate(metrics_data):\n",
    "            num_vars = len(labels)\n",
    "            angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "            angles += angles[:1]  # Complete the circle\n",
    "            metrics_values += metrics_values[:1]\n",
    "            std_dev_values += std_dev_values[:1]\n",
    "            labels += labels[:1]\n",
    "\n",
    "            ax.fill(angles, metrics_values, color=colors[i % len(colors)], alpha=0.25)\n",
    "            ax.plot(angles, metrics_values, color=colors[i % len(colors)], linewidth=2, label=scheme_names[i])\n",
    "\n",
    "            for j in range(num_vars):\n",
    "                angle = angles[j]\n",
    "                value = metrics_values[j]\n",
    "                error = std_dev_values[j]\n",
    "                ax.errorbar(angle, value, yerr=error, fmt='o', color=colors[i % len(colors)], capsize=5, elinewidth=2)\n",
    "\n",
    "            for j in range(num_vars):\n",
    "                angle = angles[j]\n",
    "                value = metrics_values[j]\n",
    "                ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.title(f\"Stacked Radar Chart for Multiple Schemes against AI over {self.trial} trials\", size=15, color='black', y=1.1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_against_all_schemes(self):\n",
    "        metrics_data = []\n",
    "        for scheme in self.schemes:\n",
    "            labels, metrics_values, std_dev_values = self.compute_metrics(scheme, normalization_values=self.normalization_values)\n",
    "            metrics_data.append((labels, metrics_values, std_dev_values))\n",
    "        \n",
    "        self.plot_stacked_radar(metrics_data, self.schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[39m=\u001b[39m  [\u001b[39m\"\u001b[39m\u001b[39mmain_network_all_features\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmain_network_attack_path_exposure\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmain_network_exposed_endpoints\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m----> 4\u001b[0m     radar \u001b[39m=\u001b[39m RadarPlot(epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial\u001b[39m=\u001b[39;49mtrial)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Plot against all schemes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     radar\u001b[39m.\u001b[39mplot_against_all_schemes()\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mRadarPlot.__init__\u001b[0;34m(self, epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrial \u001b[39m=\u001b[39m trial\n\u001b[0;32m---> 20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalization_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_normalized_values()\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalization_values)\n",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m, in \u001b[0;36mRadarPlot.calculate_normalized_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(evaluation\u001b[39m.\u001b[39msecurity_metrics_record\u001b[39m.\u001b[39mget_record())\n\u001b[1;32m     42\u001b[0m     \u001b[39m# Extract the latest security metrics record from the simulation\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     security_metrics_trial \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39;49msecurity_metrics_record\u001b[39m.\u001b[39;49mget_record()\u001b[39m.\u001b[39;49miloc[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     44\u001b[0m     security_metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([security_metrics, pd\u001b[39m.\u001b[39mDataFrame([security_metrics_trial])], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m \u001b[39m# Calculate median for normalization\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1754\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "models =  [\"main_network_all_features\", \"main_network_attack_path_exposure\", \"main_network_exposed_endpoints\"]\n",
    "\n",
    "for model in models:\n",
    "    radar = RadarPlot(epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial=trial)\n",
    "    # Plot against all schemes\n",
    "    radar.plot_against_all_schemes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

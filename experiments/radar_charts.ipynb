{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_directory = os.getcwd()\n",
    "if not os.path.exists(current_directory + '\\\\experimental_data'):\n",
    "    os.makedirs(current_directory + '\\\\experimental_data')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\plots')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\results')\n",
    "sys.path.append(current_directory.replace('experiments', ''))\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.set_loglevel('WARNING')\n",
    "from run import execute_simulation, create_experiment_snapshots, execute_ai_model\n",
    "from mtdnetwork.mtd.completetopologyshuffle import CompleteTopologyShuffle\n",
    "from mtdnetwork.mtd.ipshuffle import IPShuffle\n",
    "from mtdnetwork.mtd.hosttopologyshuffle import HostTopologyShuffle\n",
    "from mtdnetwork.mtd.portshuffle import PortShuffle\n",
    "from mtdnetwork.mtd.osdiversity import OSDiversity\n",
    "from mtdnetwork.mtd.servicediversity import ServiceDiversity\n",
    "from mtdnetwork.mtd.usershuffle import UserShuffle\n",
    "from mtdnetwork.mtd.osdiversityassignment import OSDiversityAssignment\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment_snapshots([25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters\n",
    "epsilon = 1.0  # exploration rate\n",
    "\n",
    "# Simulator Settings\n",
    "start_time = 0\n",
    "finish_time = 3000\n",
    "mtd_interval = 100\n",
    "total_nodes = 300\n",
    "new_network = True\n",
    "features = [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\",  \"overall_asr_avg\", \"roa\", \"shortest_path_variability\", \"risk\"]\n",
    "model = \"main_network_final_host_compromise_ratio#exposed_endpoints#attack_path_exposure#overall_asr_avg#roa#shortest_path_variability#risk\"\n",
    "trial = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RadarPlot:\n",
    "    def __init__(self, epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, trial):\n",
    "        # Learning Parameters\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "\n",
    "        # Simulator Settings\n",
    "        self.start_time = start_time\n",
    "        self.finish_time = finish_time\n",
    "        self.mtd_interval = mtd_interval\n",
    "        self.schemes = ['simultaneous', 'random', 'alternative']\n",
    "        self.total_nodes = total_nodes\n",
    "        self.new_network = new_network\n",
    "        self.features = features\n",
    "        self.model = model\n",
    "        self.trial = trial\n",
    "        self.normalization_values = {scheme: self.calculate_normalized_values(scheme) for scheme in self.schemes}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_normalized_values(self, scheme):\n",
    "        # DataFrame to store the results of each trial\n",
    "        security_metrics = pd.DataFrame(columns=self.features)\n",
    "\n",
    "        for _ in range(self.trial):\n",
    "            # Execute the AI model and collect the results\n",
    "            evaluation = execute_ai_model(\n",
    "                model=self.model, \n",
    "                features=self.features, \n",
    "                start_time=self.start_time, \n",
    "                finish_time=self.finish_time, \n",
    "                mtd_interval=self.mtd_interval, \n",
    "                scheme=scheme, \n",
    "                total_nodes=self.total_nodes, \n",
    "                new_network=self.new_network\n",
    "            )\n",
    "            # Extract the latest security metrics record\n",
    "            security_metrics_trial = evaluation.security_metrics_record.get_record().drop('times', axis=1).iloc[-1]\n",
    "            security_metrics = pd.concat([security_metrics, pd.DataFrame([security_metrics_trial])], ignore_index=True)\n",
    "\n",
    "        # Calculate median for normalization\n",
    "        normalized_values = security_metrics.median().to_dict()\n",
    "\n",
    "        return normalized_values\n",
    "    \n",
    "    def compute_metrics(self, normalization_values=None):\n",
    "            # DataFrame to store the results of each trial\n",
    "            security_metrics = pd.DataFrame(columns=self.features)\n",
    "\n",
    "            for _ in range(self.trial):\n",
    "                # Execute the AI model and collect the results\n",
    "                evaluation = execute_ai_model(\n",
    "                    model=self.model,\n",
    "                    features=self.features,\n",
    "                    start_time=self.start_time,\n",
    "                    finish_time=self.finish_time,\n",
    "                    mtd_interval=self.mtd_interval,\n",
    "                    scheme='mtd_ai',\n",
    "                    total_nodes=self.total_nodes,\n",
    "                    new_network=self.new_network\n",
    "                )\n",
    "                # Extract the latest security metrics record\n",
    "                security_metrics_trial = evaluation.security_metrics_record.get_record().drop('times', axis=1).iloc[-1]\n",
    "                security_metrics = pd.concat([security_metrics, pd.DataFrame([security_metrics_trial])], ignore_index=True)\n",
    "\n",
    "            # Normalize each column if normalization values are provided\n",
    "            if normalization_values:\n",
    "                for column, norm_value in normalization_values.items():\n",
    "                    if column in security_metrics.columns:\n",
    "                        if column in [\"host_compromise_ratio\", \"exposed_endpoints\", \"attack_path_exposure\", \"risk\"]:\n",
    "                            security_metrics[column] = 1 / (security_metrics[column] / norm_value)\n",
    "                        else:\n",
    "                            security_metrics[column] = security_metrics[column] / norm_value\n",
    "\n",
    "            # Calculate median and standard deviation for each metric\n",
    "            results = {\n",
    "                'Median': security_metrics.median(),\n",
    "                'Standard Deviation': security_metrics.std()\n",
    "            }\n",
    "\n",
    "            # Convert results to a DataFrame\n",
    "            results_security_metrics = pd.DataFrame(results).dropna()\n",
    "\n",
    "            # Extract data for the radar plot\n",
    "            metrics_values = results_security_metrics['Median'].tolist()\n",
    "            labels = results_security_metrics.index.tolist()\n",
    "\n",
    "            return labels, metrics_values, results_security_metrics['Standard Deviation'].tolist()\n",
    "    \n",
    "\n",
    "    def plot_radar(self, labels, metrics_values, std_dev_values, scheme):\n",
    "        # Number of metrics\n",
    "        num_vars = len(labels)\n",
    "\n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        metrics_values += metrics_values[:1]\n",
    "        std_dev_values += std_dev_values[:1]\n",
    "        labels += labels[:1]  # Close the circle by repeating the first label\n",
    "\n",
    "        # Create radar plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Plot data\n",
    "        ax.fill(angles, metrics_values, color='blue', alpha=0.25)\n",
    "        ax.plot(angles, metrics_values, color='blue', linewidth=2, label='Median')\n",
    "\n",
    "        # Add error bars\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = metrics_values[i]\n",
    "            error = std_dev_values[i]\n",
    "            ax.errorbar(angle, value, yerr=error, fmt='o', color='blue', capsize=5, elinewidth=2)\n",
    "\n",
    "        # Add score labels\n",
    "        for i in range(num_vars):\n",
    "            angle = angles[i]\n",
    "            value = metrics_values[i]\n",
    "            ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        # Labels\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])  # Set ticks without the last angle\n",
    "        ax.set_xticklabels(labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.title(f\"Radar chart with AI with all 4 single MTD (compare to {scheme}) over {self.trial} trials\", size=15, color='blue', y=1.1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_stacked_radar(self, metrics_data, scheme_names):\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Define colors for each scheme\n",
    "        colors = ['blue', 'green', 'red', 'orange', 'purple', 'cyan']\n",
    "\n",
    "        for i, (labels, metrics_values, std_dev_values) in enumerate(metrics_data):\n",
    "            num_vars = len(labels)\n",
    "            angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "            angles += angles[:1]  # Complete the circle\n",
    "            metrics_values += metrics_values[:1]\n",
    "            std_dev_values += std_dev_values[:1]\n",
    "            labels += labels[:1]\n",
    "\n",
    "            ax.fill(angles, metrics_values, color=colors[i % len(colors)], alpha=0.25)\n",
    "            ax.plot(angles, metrics_values, color=colors[i % len(colors)], linewidth=2, label=scheme_names[i])\n",
    "\n",
    "            for j in range(num_vars):\n",
    "                angle = angles[j]\n",
    "                value = metrics_values[j]\n",
    "                error = std_dev_values[j]\n",
    "                ax.errorbar(angle, value, yerr=error, fmt='o', color=colors[i % len(colors)], capsize=5, elinewidth=2)\n",
    "\n",
    "            for j in range(num_vars):\n",
    "                angle = angles[j]\n",
    "                value = metrics_values[j]\n",
    "                ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(labels[:-1], rotation=45, ha='right')\n",
    "\n",
    "        plt.title(f\"Stacked Radar Chart for Multiple Schemes against AI over {self.trial} trials\", size=15, color='black', y=1.1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_against_all_schemes(self):\n",
    "        metrics_data = []\n",
    "        for scheme in self.schemes:\n",
    "            labels, metrics_values, std_dev_values = self.compute_metrics(normalization_values=self.normalization_values[scheme])\n",
    "            metrics_data.append((labels, metrics_values, std_dev_values))\n",
    "        \n",
    "        self.plot_stacked_radar(metrics_data, self.schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "models =  [\"main_network_all_features\", \"main_network_attack_path_exposure\", \"main_network_exposed_endpoints\"]\n",
    "\n",
    "for model in models:\n",
    "    radar = RadarPlot(epsilon, start_time, finish_time, mtd_interval, total_nodes, new_network, features, model, 5)\n",
    "    # Define the schemes and normalization values\n",
    "    schemes = radar.schemes\n",
    "    normalization_values = radar.normalization_values\n",
    "    # Plot against all schemes\n",
    "    radar.plot_against_all_schemes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming your CSV data is saved as 'data.csv'\n",
    "data = pd.read_csv('data_processing/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU:\", gpu)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# One-hot encoding for categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data[['curr_attack', 'interrupted']])\n",
    "encoded_labels = pd.get_dummies(data['mtd'])\n",
    "\n",
    "# Combine one-hot encoded features with other numerical features\n",
    "features = pd.concat([pd.DataFrame(encoded_features), data[['mtd_freq', 'compromised_num']]], axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamho/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Output layer: 4 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2852 - loss: 5.8118\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3320 - loss: 2.0976\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3314 - loss: 1.8456\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2950 - loss: 1.6757\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2415 - loss: 1.7717\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2981 - loss: 1.5128\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3060 - loss: 1.4619\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3319 - loss: 1.4118\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3538 - loss: 1.4192\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3464 - loss: 1.5173\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3509 - loss: 1.4090\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4208 - loss: 1.4345\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3754 - loss: 1.4026\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3603 - loss: 1.2856\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4985 - loss: 1.2516\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4501 - loss: 1.3133\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4763 - loss: 1.2294\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4764 - loss: 1.2664\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3985 - loss: 1.3366\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2678 - loss: 1.4223\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4239 - loss: 1.4172\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5018 - loss: 1.5293\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4123 - loss: 1.1797\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5190 - loss: 1.1205\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4958 - loss: 1.1140\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5591 - loss: 0.9940\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 1.0310\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5656 - loss: 1.0003\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3911 - loss: 1.1045\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5452 - loss: 1.0058\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4874 - loss: 1.1012\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5800 - loss: 1.0604\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5455 - loss: 1.0365\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5651 - loss: 0.8868\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4890 - loss: 1.0936\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4680 - loss: 0.9635\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5307 - loss: 0.9021\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6066 - loss: 0.9058\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5417 - loss: 0.9182\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5112 - loss: 1.0919\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5433 - loss: 0.8651\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5635 - loss: 0.8714\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6028 - loss: 0.7742\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5978 - loss: 0.7279\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5835 - loss: 0.7334\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5965 - loss: 0.7255\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5736 - loss: 0.7476\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5039 - loss: 0.7987\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6211 - loss: 0.7164\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5760 - loss: 0.7688\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6225 - loss: 0.7319\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4847 - loss: 0.8243\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5939 - loss: 0.6861\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5455 - loss: 0.7423\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5711 - loss: 0.7061\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6078 - loss: 0.7981\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4961 - loss: 1.0461\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5181 - loss: 0.8169\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6024 - loss: 0.9115\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5766 - loss: 0.8669\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5984 - loss: 0.7504\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5424 - loss: 0.7568\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5918 - loss: 0.6794\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6066 - loss: 0.7755\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5990 - loss: 0.7312\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5347 - loss: 0.6793\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5815 - loss: 0.6661\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6181 - loss: 0.6856\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6099 - loss: 0.6514\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5167 - loss: 0.7200\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6007 - loss: 0.8706\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6158 - loss: 0.7194\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5732 - loss: 0.7170\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5800 - loss: 0.7974\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6217 - loss: 1.0577\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5164 - loss: 0.7531\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5983 - loss: 0.7639\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6013 - loss: 0.6913\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5865 - loss: 0.6841\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6500 - loss: 0.6482\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6341 - loss: 0.6551\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5901 - loss: 0.7551\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6700 - loss: 0.6654\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6193 - loss: 0.6383\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6953 - loss: 0.6300\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6203 - loss: 0.6835\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6440 - loss: 0.6510\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6648 - loss: 0.6671\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6246 - loss: 0.6519\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5608 - loss: 0.6981\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6998 - loss: 0.6463\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5828 - loss: 0.6768\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6896 - loss: 0.6109\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5648 - loss: 0.6795\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6889 - loss: 0.6004\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6721 - loss: 0.6464\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6320 - loss: 0.6510\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6634 - loss: 0.6857\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6249 - loss: 0.6945\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6058 - loss: 0.7287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34e2434d0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4536 - loss: 1.0918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0081708431243896, 0.47727271914482117]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With metrics as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your CSV data is saved as 'data.csv'\n",
    "data = pd.read_csv('data_processing/metrics/simulation_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamho/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "# X_train.shape[1] is the number of features in your input data\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)  # Output layer with 3 neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # Use mean squared error for regression\n",
    "              metrics=['mae'])  # You can add additional metrics like Mean Absolute Error (MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# One-hot encoding for categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data[['curr_attack', 'interrupted', 'mtd']])\n",
    "targets = data[['roa', 'impact', 'complexity']]\n",
    "\n",
    "# Combine one-hot encoded features with other numerical features\n",
    "features = pd.concat([pd.DataFrame(encoded_features), data.drop(['curr_attack', 'interrupted', 'mtd', 'roa', 'impact', 'complexity'], axis=1)], axis=1)\n",
    "features = features.drop(\"x_10000\", axis=1)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0    1    2    3    4    5    6    7    8    9  ...  x_5000  x_5500  \\\n",
       " 12  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 4   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 37  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     6.0     9.0   \n",
       " 8   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 3   0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 6   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 41  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     6.0     9.0   \n",
       " 46  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 47  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     6.0     9.0   \n",
       " 15  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 9   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 16  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 24  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 34  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     6.0     9.0   \n",
       " 31  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     6.0     9.0   \n",
       " 0   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 44  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ...     6.0     9.0   \n",
       " 27  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     6.0     0.0   \n",
       " 33  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 5   0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 29  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     6.0     9.0   \n",
       " 11  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 36  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 1   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 21  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 2   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 43  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 35  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     6.0     9.0   \n",
       " 23  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 40  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 10  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 22  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 18  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 49  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " 20  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 7   0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 42  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     6.0     9.0   \n",
       " 14  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 28  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     6.0     0.0   \n",
       " 38  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     6.0     9.0   \n",
       " \n",
       "     x_6000  x_6500  x_7000  x_7500  x_8000  x_8500  x_9000  x_9500  \n",
       " 12     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 4      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 37     9.0     4.0    10.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 8      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 3      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 6      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 41     9.0     4.0    10.0     8.0     2.0     0.0     0.0     0.0  \n",
       " 46     9.0     4.0    10.0     8.0     2.0    13.0     2.0     0.0  \n",
       " 47     9.0     4.0    10.0     8.0     2.0    13.0     7.0     0.0  \n",
       " 15     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 9      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 16     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 24     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 34     9.0     4.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 31     4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 44     9.0     4.0    10.0     8.0     2.0    13.0     0.0     0.0  \n",
       " 27     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 33     9.0     4.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 5      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 29     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 11     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 36     9.0     4.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 1      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 21     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 2      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 43     9.0     4.0    10.0     8.0     2.0     6.0     0.0     0.0  \n",
       " 35     9.0     4.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 23     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 40     9.0     4.0    10.0     8.0     0.0     0.0     0.0     0.0  \n",
       " 10     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 22     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 18     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 49     9.0     4.0    10.0     8.0     2.0    13.0     7.0     0.0  \n",
       " 20     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 7      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 42     9.0     4.0    10.0     8.0     2.0     0.0     0.0     0.0  \n",
       " 14     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 28     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 38     9.0     4.0    10.0     4.0     0.0     0.0     0.0     0.0  \n",
       " \n",
       " [40 rows x 33 columns],\n",
       "           roa    impact  complexity\n",
       " 12   6.417051  4.954002    0.685664\n",
       " 4    1.342061  5.304484    0.634093\n",
       " 37  11.838206  4.900047    0.679961\n",
       " 8    1.273874  5.364134    0.627599\n",
       " 3    1.342061  5.304484    0.634093\n",
       " 6    1.317444  5.406891    0.627545\n",
       " 41  11.274985  4.953937    0.677563\n",
       " 46  10.931931  5.016954    0.688501\n",
       " 47  10.690001  5.022268    0.688983\n",
       " 15   6.009297  4.694617    0.685711\n",
       " 9    3.155312  4.802075    0.651736\n",
       " 16   6.009297  4.694617    0.685711\n",
       " 24  15.137241  5.054555    0.690144\n",
       " 34  11.873003  4.839083    0.672210\n",
       " 31  12.594545  4.853602    0.677293\n",
       " 0    0.000000  0.000000    0.000000\n",
       " 44  11.029447  5.018186    0.687678\n",
       " 27  13.823837  5.044117    0.683666\n",
       " 33  11.873003  4.839083    0.672210\n",
       " 5    1.342061  5.304484    0.634093\n",
       " 29  12.966029  4.941025    0.680368\n",
       " 11   6.950770  5.060195    0.683918\n",
       " 36  11.873003  4.839083    0.672210\n",
       " 1    0.000000  0.000000    0.000000\n",
       " 21  17.280075  4.853177    0.682704\n",
       " 2    1.346500  5.547139    0.632123\n",
       " 43  11.172508  4.964924    0.681883\n",
       " 35  11.873003  4.839083    0.672210\n",
       " 23  15.271350  5.082490    0.691026\n",
       " 40  11.403308  4.975461    0.677876\n",
       " 10   7.406380  5.167764    0.679862\n",
       " 22  16.225416  4.938858    0.683353\n",
       " 18  19.721559  4.902469    0.680323\n",
       " 49  10.690001  5.022268    0.688983\n",
       " 20  17.280075  4.853177    0.682704\n",
       " 7    1.317444  5.406891    0.627545\n",
       " 42  11.274985  4.953937    0.677563\n",
       " 14   6.417051  4.954002    0.685664\n",
       " 28  13.823837  5.044117    0.683666\n",
       " 38  11.648906  4.945626    0.680237)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 83.8700 - mae: 7.4520\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 23.3918 - mae: 4.0503\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.9943 - mae: 1.9454\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 12.0438 - mae: 2.4035\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.9981 - mae: 2.7518\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 12.7928 - mae: 2.6702\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.1835 - mae: 2.2748\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.8189 - mae: 1.7448\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8808 - mae: 1.4115\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.5218 - mae: 1.2849\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.3938 - mae: 1.2794\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2349 - mae: 1.3507\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.5279 - mae: 1.3680\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.6950 - mae: 1.1428\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.5936 - mae: 0.9116\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8820 - mae: 0.9257\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.1931 - mae: 0.9490\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3463 - mae: 0.9764\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1139 - mae: 0.9339\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6147 - mae: 0.8740\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5136 - mae: 0.7558\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3866 - mae: 0.6699\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4592 - mae: 0.5759\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2643 - mae: 0.6090\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3456 - mae: 0.6238\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3618 - mae: 0.6207\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1924 - mae: 0.5458\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0554 - mae: 0.5325\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2413 - mae: 0.5328\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6120 - mae: 0.5478\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0331 - mae: 0.5253\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0114 - mae: 0.4904\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9241 - mae: 0.5219\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8669 - mae: 0.5042\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8322 - mae: 0.4611\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8039 - mae: 0.4721\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9088 - mae: 0.4713\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7982 - mae: 0.4634\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8188 - mae: 0.3969\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7260 - mae: 0.4349\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7168 - mae: 0.4371\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7007 - mae: 0.3933\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6892 - mae: 0.4045\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7149 - mae: 0.4016\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7009 - mae: 0.3985\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6431 - mae: 0.3868\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6303 - mae: 0.3814\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6184 - mae: 0.3830\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6235 - mae: 0.3699\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9236 - mae: 0.3635\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5606 - mae: 0.3949\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5920 - mae: 0.3726\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8511 - mae: 0.3416\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6309 - mae: 0.3531\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8211 - mae: 0.3305\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5920 - mae: 0.3503\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8355 - mae: 0.3184\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4999 - mae: 0.3512\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7923 - mae: 0.3144\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7218 - mae: 0.3219\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4733 - mae: 0.3483\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4579 - mae: 0.3568\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7227 - mae: 0.3081\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5215 - mae: 0.3180\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4850 - mae: 0.3158\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4664 - mae: 0.3278\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4348 - mae: 0.3410\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4196 - mae: 0.3157\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6356 - mae: 0.2811\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4644 - mae: 0.3230\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4549 - mae: 0.3338\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6422 - mae: 0.2821\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3683 - mae: 0.2964\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4028 - mae: 0.2869\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3929 - mae: 0.2776\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3358 - mae: 0.2903\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3683 - mae: 0.2766\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3361 - mae: 0.2786\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5196 - mae: 0.2608\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3733 - mae: 0.2590\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3533 - mae: 0.2766\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4784 - mae: 0.2516\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3020 - mae: 0.2778\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3345 - mae: 0.2614\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3473 - mae: 0.2480\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3025 - mae: 0.2541\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4986 - mae: 0.2275\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2710 - mae: 0.2654\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4153 - mae: 0.2787\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3096 - mae: 0.2853\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3222 - mae: 0.2473\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2858 - mae: 0.2764\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2830 - mae: 0.2749\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2534 - mae: 0.2347\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3665 - mae: 0.2358\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3470 - mae: 0.2460\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3243 - mae: 0.2408\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2447 - mae: 0.2440\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3438 - mae: 0.2362\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2156 - mae: 0.2730\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1883 - mae: 0.2433\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2108 - mae: 0.2257\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1803 - mae: 0.2412\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1794 - mae: 0.2153\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1775 - mae: 0.2225\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2628 - mae: 0.1986\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1563 - mae: 0.2172\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2041 - mae: 0.2585\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1586 - mae: 0.1991\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1786 - mae: 0.2477\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1666 - mae: 0.2299\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1453 - mae: 0.2162\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1587 - mae: 0.2497\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2127 - mae: 0.1820\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1267 - mae: 0.1979\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1326 - mae: 0.2156\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1716 - mae: 0.1717\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1740 - mae: 0.1834\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1255 - mae: 0.2001\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1055 - mae: 0.1787\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1158 - mae: 0.1956\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1528 - mae: 0.1633\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1137 - mae: 0.1932\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1744 - mae: 0.1883\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0959 - mae: 0.1731\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1522 - mae: 0.1661\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1113 - mae: 0.1639\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0871 - mae: 0.1777\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0801 - mae: 0.1729\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0783 - mae: 0.1667\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0768 - mae: 0.1633\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1050 - mae: 0.1462\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0771 - mae: 0.1644\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0747 - mae: 0.1656\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1006 - mae: 0.1527\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0682 - mae: 0.1561\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1011 - mae: 0.1436\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0637 - mae: 0.1531\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0577 - mae: 0.1490\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0590 - mae: 0.1462\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0556 - mae: 0.1480\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0536 - mae: 0.1421\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0497 - mae: 0.1392\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0668 - mae: 0.1292\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0484 - mae: 0.1365\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0499 - mae: 0.1350\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0549 - mae: 0.1283\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0460 - mae: 0.1296\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0449 - mae: 0.1312\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0507 - mae: 0.1261\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0441 - mae: 0.1288\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0471 - mae: 0.1200\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0396 - mae: 0.1200\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0374 - mae: 0.1197\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0381 - mae: 0.1190\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0351 - mae: 0.1193\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0349 - mae: 0.1196\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0358 - mae: 0.1117\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0387 - mae: 0.1099\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0382 - mae: 0.1090\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0322 - mae: 0.1112\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0315 - mae: 0.1101\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0306 - mae: 0.1153\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0317 - mae: 0.1150\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0293 - mae: 0.1105\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0322 - mae: 0.1022\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0273 - mae: 0.1027\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0262 - mae: 0.1003\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0298 - mae: 0.0959\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0257 - mae: 0.0981\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0255 - mae: 0.1027\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0271 - mae: 0.0941\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0391 - mae: 0.0923\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0233 - mae: 0.0934\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0239 - mae: 0.1039\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0248 - mae: 0.0963\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0256 - mae: 0.1025\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0246 - mae: 0.0967\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0275 - mae: 0.0928\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0212 - mae: 0.0980\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0279 - mae: 0.0915\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0208 - mae: 0.1014\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0251 - mae: 0.1067\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0212 - mae: 0.0910\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0214 - mae: 0.0967\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0194 - mae: 0.0910\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0192 - mae: 0.0830\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0175 - mae: 0.0825\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0164 - mae: 0.0896\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0154 - mae: 0.0855\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0196 - mae: 0.0822\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0148 - mae: 0.0805\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0183 - mae: 0.0759\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0149 - mae: 0.0807\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0170 - mae: 0.0788\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0144 - mae: 0.0804\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0154 - mae: 0.0816\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0151 - mae: 0.0832\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0171 - mae: 0.0693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3680af250>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1103 - mae: 0.2078\n",
      "Test loss: 0.11030024290084839, Test accuracy: 0.20782466232776642\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.21095   ,  4.975697  ,  0.50890344],\n",
       "       [11.468366  ,  4.991055  ,  0.5927972 ],\n",
       "       [12.760562  ,  4.88564   ,  0.5520267 ],\n",
       "       [11.206697  ,  5.0467525 ,  0.7722778 ],\n",
       "       [18.423183  ,  4.730998  ,  0.30904523],\n",
       "       [10.755659  ,  5.0182037 ,  0.5662274 ],\n",
       "       [14.093618  ,  5.1330686 ,  0.8299069 ],\n",
       "       [15.075996  ,  5.1143527 ,  0.73296684],\n",
       "       [12.836745  ,  4.816085  ,  0.5013551 ],\n",
       "       [18.95535   ,  4.7499576 ,  0.3903083 ]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)# Plot predicted vs actual values\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y_pred - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13   -0.206101\n",
       "39    0.065057\n",
       "30   -0.205467\n",
       "45    0.177250\n",
       "17   -1.298375\n",
       "48    0.065658\n",
       "26    0.269782\n",
       "25    0.665451\n",
       "32    0.652447\n",
       "19    0.354122\n",
       "Name: roa, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred - y_test)['roa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.21095 , 11.468366, 12.760562, 11.206697, 18.423183, 10.755659,\n",
       "        14.093618, 15.075996, 12.836745, 18.95535 ], dtype=float32),\n",
       " 13     6.417051\n",
       " 39    11.403308\n",
       " 30    12.966029\n",
       " 45    11.029447\n",
       " 17    19.721559\n",
       " 48    10.690001\n",
       " 26    13.823837\n",
       " 25    14.410546\n",
       " 32    12.184298\n",
       " 19    18.601229\n",
       " Name: roa, dtype: float64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0], y_test['roa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtdsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

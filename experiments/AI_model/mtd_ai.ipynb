{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming your CSV data is saved as 'data.csv'\n",
    "data = pd.read_csv('data_processing/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU:\", gpu)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# One-hot encoding for categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data[['curr_attack', 'interrupted']])\n",
    "encoded_labels = pd.get_dummies(data['mtd'])\n",
    "\n",
    "# Combine one-hot encoded features with other numerical features\n",
    "features = pd.concat([pd.DataFrame(encoded_features), data[['mtd_freq', 'compromised_num']]], axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamho/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-02 11:32:03.315667: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-04-02 11:32:03.315686: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-02 11:32:03.315691: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-02 11:32:03.315717: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-02 11:32:03.315732: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Output layer: 4 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4494 - mae: 0.3874\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3038 - mae: 0.2483\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3829 - mae: 0.3668\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5112 - mae: 0.2571\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4985 - mae: 0.2869\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2707 - mae: 0.2502\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3979 - mae: 0.1963\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2784 - mae: 0.2590\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2401 - mae: 0.2239\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2609 - mae: 0.2508\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2216 - mae: 0.2286\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2165 - mae: 0.1990\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2228 - mae: 0.2176\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2080 - mae: 0.1883\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2000 - mae: 0.1912\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1960 - mae: 0.1890\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1967 - mae: 0.1767\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3297 - mae: 0.1684\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3107 - mae: 0.1562\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1745 - mae: 0.1966\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2956 - mae: 0.1821\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2754 - mae: 0.1934\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2865 - mae: 0.2438\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1670 - mae: 0.2111\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1799 - mae: 0.2043\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1558 - mae: 0.2072\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1525 - mae: 0.2009\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1573 - mae: 0.1953\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1400 - mae: 0.1733\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1471 - mae: 0.1828\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1359 - mae: 0.1680\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1384 - mae: 0.1883\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1299 - mae: 0.1662\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1984 - mae: 0.1450\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1365 - mae: 0.1795\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1162 - mae: 0.1739\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1273 - mae: 0.1800\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1183 - mae: 0.1874\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1102 - mae: 0.1677\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1218 - mae: 0.1717\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1080 - mae: 0.1442\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1108 - mae: 0.1729\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1794 - mae: 0.1473\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1641 - mae: 0.1295\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1655 - mae: 0.1718\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1506 - mae: 0.1526\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0970 - mae: 0.1676\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1101 - mae: 0.1744\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1186 - mae: 0.1869\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1079 - mae: 0.1555\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1535 - mae: 0.1777\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0954 - mae: 0.1820\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0818 - mae: 0.1567\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0835 - mae: 0.1485\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1342 - mae: 0.1560\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0849 - mae: 0.1253\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0820 - mae: 0.1453\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1241 - mae: 0.1479\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0728 - mae: 0.1499\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0672 - mae: 0.1373\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0700 - mae: 0.1538\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0613 - mae: 0.1276\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0597 - mae: 0.1273\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0594 - mae: 0.1260\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0589 - mae: 0.1169\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0967 - mae: 0.1117\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0630 - mae: 0.1105\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0573 - mae: 0.1249\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0537 - mae: 0.1098\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0515 - mae: 0.1173\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0579 - mae: 0.1183\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0513 - mae: 0.1170\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0506 - mae: 0.1093\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0479 - mae: 0.1091\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0739 - mae: 0.1068\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0476 - mae: 0.1161\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0466 - mae: 0.1018\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0732 - mae: 0.1084\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0441 - mae: 0.1111\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0420 - mae: 0.1048\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0462 - mae: 0.1195\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0405 - mae: 0.1041\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0388 - mae: 0.1048\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0561 - mae: 0.0942\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0451 - mae: 0.1075\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0643 - mae: 0.1010\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0432 - mae: 0.1049\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0387 - mae: 0.1051\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0348 - mae: 0.1042\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0355 - mae: 0.0884\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.0904\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0501 - mae: 0.0970\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0469 - mae: 0.0806\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0371 - mae: 0.1066\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0331 - mae: 0.0922\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0310 - mae: 0.0923\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0322 - mae: 0.1038\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0317 - mae: 0.0877\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0282 - mae: 0.0984\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0295 - mae: 0.0892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x329ba9590>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0327 - mae: 0.1298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.032660502940416336, 0.12983328104019165]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With metrics as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your CSV data is saved as 'data.csv'\n",
    "data = pd.read_csv('data_processing/metrics/simulation_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamho/Downloads/kaggle_keras/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "# X_train.shape[1] is the number of features in your input data\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)  # Output layer with 3 neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # Use mean squared error for regression\n",
    "              metrics=['mae'])  # You can add additional metrics like Mean Absolute Error (MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# One-hot encoding for categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data[['curr_attack', 'interrupted', 'mtd']])\n",
    "targets = data[['roa', 'impact', 'complexity']]\n",
    "\n",
    "# Combine one-hot encoded features with other numerical features\n",
    "features = pd.concat([pd.DataFrame(encoded_features), data.drop(['curr_attack', 'interrupted', 'mtd', 'roa', 'impact', 'complexity'], axis=1)], axis=1)\n",
    "features = features.drop(\"x_10000\", axis=1)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_5000</th>\n",
       "      <th>x_5500</th>\n",
       "      <th>x_6000</th>\n",
       "      <th>x_6500</th>\n",
       "      <th>x_7000</th>\n",
       "      <th>x_7500</th>\n",
       "      <th>x_8000</th>\n",
       "      <th>x_8500</th>\n",
       "      <th>x_9000</th>\n",
       "      <th>x_9500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9  ...  x_5000  x_5500  \\\n",
       "0   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "1   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "2   0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "3   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "4   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "5   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "6   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "7   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "8   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "9   0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "10  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "11  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "12  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "13  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "14  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "15  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "16  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "17  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       "18  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "19  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "20  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "21  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "22  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "23  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "24  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       "25  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "26  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "27  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       "28  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "29  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       "30  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       "31  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "32  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       "33  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "34  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       "35  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       "36  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       "37  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       "38  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       "39  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "40  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       "41  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "42  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "43  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       "44  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "45  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       "46  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       "47  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       "48  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       "49  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       "\n",
       "    x_6000  x_6500  x_7000  x_7500  x_8000  x_8500  x_9000  x_9500  \n",
       "0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "1      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "3      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "4      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "5      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "6      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "7      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "8      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "9      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "10     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "11     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "12     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "13     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "14     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "15     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "16     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "17     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "18     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "19     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "20     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "21     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "22     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "23     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "24     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "25     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "26     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "27     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "28     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "29     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "30     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "31     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "32     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "33     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "34     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "35     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "36     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "37     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "38     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "39     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "40     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "41     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "42     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "43     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "44     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "45     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "46     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "47     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "48     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       "49     5.0     0.0     0.0     0.0     0.0     4.0     0.0     3.0  \n",
       "\n",
       "[50 rows x 33 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0    1    2    3    4    5    6    7    8    9  ...  x_5000  x_5500  \\\n",
       " 12  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 4   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 37  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       " 8   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 3   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 6   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 41  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 46  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       " 47  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 15  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 9   0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 16  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 24  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 34  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       " 31  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 0   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 44  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 27  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 33  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 5   0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 29  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       " 11  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 36  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       " 1   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 21  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 2   0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 43  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       " 35  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       " 23  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 40  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...     9.0     1.0   \n",
       " 10  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 22  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     0.0     0.0   \n",
       " 18  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 49  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     9.0     1.0   \n",
       " 20  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     0.0     0.0   \n",
       " 7   0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       " 42  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 14  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...     0.0     0.0   \n",
       " 28  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...     9.0     1.0   \n",
       " 38  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...     9.0     1.0   \n",
       " \n",
       "     x_6000  x_6500  x_7000  x_7500  x_8000  x_8500  x_9000  x_9500  \n",
       " 12     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 4      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 37     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 8      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 3      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 6      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 41     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 46     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       " 47     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       " 15     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 9      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 16     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 24     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 34     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 31     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 44     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       " 27     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 33     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 5      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 29     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 11     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 36     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 1      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 21     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 2      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 43     5.0     0.0     0.0     0.0     0.0     4.0     0.0     0.0  \n",
       " 35     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 23     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 40     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 10     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 22     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 18     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 49     5.0     0.0     0.0     0.0     0.0     4.0     0.0     3.0  \n",
       " 20     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 7      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 42     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 14     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 28     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " 38     5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       " \n",
       " [40 rows x 33 columns],\n",
       "           roa    impact  complexity\n",
       " 12  20.743055  4.526117    0.739695\n",
       " 4   56.524889  4.518834    0.796893\n",
       " 37  10.716184  4.565010    0.713422\n",
       " 8   26.716731  4.584323    0.767330\n",
       " 3   56.524889  4.518834    0.796893\n",
       " 6   56.524889  4.518834    0.796893\n",
       " 41  10.716184  4.565010    0.713422\n",
       " 46  10.460009  4.577118    0.714388\n",
       " 47  10.460009  4.577118    0.714388\n",
       " 15  15.862263  4.381347    0.722563\n",
       " 9   26.716731  4.584323    0.767330\n",
       " 16  14.589183  4.381640    0.729570\n",
       " 24  11.868409  4.638816    0.721665\n",
       " 34  10.716184  4.565010    0.713422\n",
       " 31  10.716184  4.565010    0.713422\n",
       " 0    0.000000  0.000000    9.000000\n",
       " 44  10.460009  4.577118    0.714388\n",
       " 27  11.868409  4.638816    0.721665\n",
       " 33  10.716184  4.565010    0.713422\n",
       " 5   56.524889  4.518834    0.796893\n",
       " 29  11.100651  4.606530    0.718043\n",
       " 11  20.743055  4.526117    0.739695\n",
       " 36  10.716184  4.565010    0.713422\n",
       " 1    0.000000  0.000000    9.000000\n",
       " 21  13.592229  4.330779    0.722381\n",
       " 2   56.524889  4.518834    0.796893\n",
       " 43  10.460009  4.577118    0.714388\n",
       " 35  10.716184  4.565010    0.713422\n",
       " 23  12.953468  4.310874    0.716586\n",
       " 40  10.716184  4.565010    0.713422\n",
       " 10  21.108488  4.595349    0.739277\n",
       " 22  13.592229  4.330779    0.722381\n",
       " 18  14.589183  4.381640    0.729570\n",
       " 49  10.248183  4.535724    0.711288\n",
       " 20  13.592229  4.330779    0.722381\n",
       " 7   33.656328  4.286083    0.728037\n",
       " 42  10.716184  4.565010    0.713422\n",
       " 14  17.792915  4.503570    0.734394\n",
       " 28  11.100651  4.606530    0.718043\n",
       " 38  10.716184  4.565010    0.713422)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 153.4276 - mae: 7.8626\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 154.4633 - mae: 5.2165\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 126.7452 - mae: 4.6622\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 127.3432 - mae: 5.4303\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 139.3602 - mae: 5.7040\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 134.5276 - mae: 5.5027\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 96.0942 - mae: 5.1513 \n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 84.2042 - mae: 4.4942 \n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 78.5975 - mae: 3.8508 \n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 76.2382 - mae: 3.5238 \n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 73.9646 - mae: 3.6873 \n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 107.6733 - mae: 3.1117\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 101.1229 - mae: 2.6525\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 62.7084 - mae: 3.1647\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 91.3156 - mae: 2.9646\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 67.0728 - mae: 3.2635\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 53.6473 - mae: 3.1988\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 59.2609 - mae: 2.6571\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 57.1374 - mae: 2.5610\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 54.3064 - mae: 2.6275\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 51.1557 - mae: 2.5981\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 47.7585 - mae: 2.4535\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 45.4561 - mae: 2.3450\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 35.6203 - mae: 2.5232\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 39.1964 - mae: 2.2951\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 31.2094 - mae: 2.3021\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 38.8728 - mae: 2.0247\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 31.1422 - mae: 2.0764\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 33.1679 - mae: 1.9389\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 26.7682 - mae: 1.9907\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.3804 - mae: 2.0067\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.6123 - mae: 1.8573\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.8895 - mae: 1.7800\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18.0518 - mae: 1.7116\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.6421 - mae: 1.7259\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.6040 - mae: 1.4876\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.1287 - mae: 1.5616\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.6229 - mae: 1.5637\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.2122 - mae: 1.2517\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.2472 - mae: 1.3372\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.8588 - mae: 1.2397\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5007 - mae: 1.1748\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.9990 - mae: 1.1383\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.2503 - mae: 1.0316\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6223 - mae: 0.9852\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.1196 - mae: 0.9721\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3063 - mae: 0.9177\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0127 - mae: 0.8366\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.7220 - mae: 0.7971\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.7515 - mae: 0.7381\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3497 - mae: 0.7153\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2378 - mae: 0.6907\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0264 - mae: 0.6685\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9226 - mae: 0.6348\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8792 - mae: 0.5981\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7547 - mae: 0.5931\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7549 - mae: 0.5462\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4859 - mae: 0.5674\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5650 - mae: 0.5282\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4833 - mae: 0.5025\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3265 - mae: 0.5023\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2700 - mae: 0.4849\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1911 - mae: 0.4878\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2225 - mae: 0.4332\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1835 - mae: 0.4749\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0556 - mae: 0.4235\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0798 - mae: 0.4510\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0071 - mae: 0.3951\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9668 - mae: 0.4016\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9758 - mae: 0.4108\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9027 - mae: 0.3657\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9273 - mae: 0.4017\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8679 - mae: 0.3459\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5254 - mae: 0.3036\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8155 - mae: 0.3219\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7749 - mae: 0.3326\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7537 - mae: 0.3341\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7035 - mae: 0.3370\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6955 - mae: 0.3229\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6692 - mae: 0.3127\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6553 - mae: 0.2958\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6294 - mae: 0.2983\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6260 - mae: 0.2843\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6073 - mae: 0.2865\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5943 - mae: 0.2815\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5690 - mae: 0.2656\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0405 - mae: 0.2396\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5841 - mae: 0.3183\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5471 - mae: 0.2945\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5869 - mae: 0.3476\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5158 - mae: 0.2882\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5659 - mae: 0.3439\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5192 - mae: 0.3087\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4971 - mae: 0.2959\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4739 - mae: 0.2784\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8692 - mae: 0.2327\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4594 - mae: 0.2490\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4302 - mae: 0.2710\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4257 - mae: 0.2609\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7207 - mae: 0.2114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31e89af10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x2fad63060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1726 - mae: 0.3155\n",
      "Test loss: 0.17256934940814972, Test accuracy: 0.31549137830734253\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17.439287  ,  4.6064115 ,  0.60653573],\n",
       "       [10.202878  ,  4.605256  ,  0.8447328 ],\n",
       "       [11.371645  ,  4.8558187 ,  0.816222  ],\n",
       "       [ 9.653186  ,  4.4664125 ,  0.7556606 ],\n",
       "       [14.166204  ,  4.3459797 ,  0.9513207 ],\n",
       "       [ 9.811687  ,  4.5867662 ,  0.6965142 ],\n",
       "       [10.9871855 ,  3.9520504 ,  0.42982465],\n",
       "       [10.877791  ,  4.113431  ,  0.45708305],\n",
       "       [10.146969  ,  4.2696075 ,  0.8372858 ],\n",
       "       [13.465452  ,  4.4619637 ,  0.5617669 ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)# Plot predicted vs actual values\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y_pred - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13   -0.353628\n",
       "39   -0.513306\n",
       "30    0.270994\n",
       "45   -0.806823\n",
       "17   -0.422978\n",
       "48   -0.648322\n",
       "26   -0.881224\n",
       "25   -0.990618\n",
       "32   -0.569215\n",
       "19   -0.405921\n",
       "Name: roa, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred - y_test)['roa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtdsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

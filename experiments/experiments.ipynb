{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_directory = os.getcwd()\n",
    "if not os.path.exists(current_directory + '\\\\experimental_data'):\n",
    "    os.makedirs(current_directory + '\\\\experimental_data')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\plots')\n",
    "    os.makedirs(current_directory + '\\\\experimental_data\\\\results')\n",
    "sys.path.append(current_directory.replace('experiments', ''))\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.set_loglevel('WARNING')\n",
    "from run import execute_simulation, create_experiment_snapshots, execute_ai_model, single_mtd_simulation, mtd_ai_simulation, multiple_mtd_simulation, specific_multiple_mtd_simulation\n",
    "from mtdnetwork.mtd.completetopologyshuffle import CompleteTopologyShuffle\n",
    "from mtdnetwork.mtd.ipshuffle import IPShuffle\n",
    "from mtdnetwork.mtd.hosttopologyshuffle import HostTopologyShuffle\n",
    "from mtdnetwork.mtd.portshuffle import PortShuffle\n",
    "from mtdnetwork.mtd.osdiversity import OSDiversity\n",
    "from mtdnetwork.mtd.servicediversity import ServiceDiversity\n",
    "from mtdnetwork.mtd.usershuffle import UserShuffle\n",
    "from mtdnetwork.mtd.osdiversityassignment import OSDiversityAssignment\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting experiments...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters\n",
    "epsilon = 1.0  # exploration rate\n",
    "\n",
    "# Simulator Settings\n",
    "start_time = 0\n",
    "finish_time = 3000\n",
    "mtd_interval = [200]\n",
    "network_size = [25]\n",
    "total_nodes = 300\n",
    "new_network = True\n",
    "\n",
    "trial = 100\n",
    "\n",
    "mtd_strategies = [\n",
    "    CompleteTopologyShuffle,\n",
    "    # HostTopologyShuffle,\n",
    "    IPShuffle,\n",
    "    OSDiversity,\n",
    "    # PortShuffle,\n",
    "    # OSDiversityAssignment,\n",
    "    ServiceDiversity,\n",
    "    # UserShuffle\n",
    "]\n",
    "\n",
    "result_head_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network, model, trial, result_head_path):\n",
    "        # Learning Parameters\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "\n",
    "        # Simulator Settings\n",
    "        self.start_time = start_time\n",
    "        self.finish_time = finish_time\n",
    "        self.schemes = [ 'mtd_ai', 'simultaneous', 'random', 'alternative']\n",
    "        self.total_nodes = total_nodes\n",
    "        self.new_network = new_network\n",
    "        self.model = model\n",
    "        self.trial = trial\n",
    "        self.model_path = f\"AI_model/models_joo_kai/main_network_{model}.h5\"\n",
    "        self.mtd_strategies = [\n",
    "            CompleteTopologyShuffle,\n",
    "            # HostTopologyShuffle,\n",
    "            IPShuffle,\n",
    "            OSDiversity,\n",
    "            # PortShuffle,\n",
    "            # OSDiversityAssignment,\n",
    "            ServiceDiversity,\n",
    "            # UserShuffle\n",
    "        ]\n",
    "        self.mtd_interval = mtd_interval\n",
    "        self.network_size = network_size\n",
    "        self.result_head_path = result_head_path\n",
    "\n",
    "\n",
    "    def run_trials(self, scheme):\n",
    "        for i in range(self.trial):\n",
    "            if i % 100 == 0:\n",
    "                print(\"Trial_\", i)\n",
    "\n",
    "            if scheme == 'nomtd':\n",
    "                mtd = single_mtd_simulation(\"nomtd\", [None], \n",
    "                                                         mtd_interval=self.mtd_interval,network_size=self.network_size) \n",
    "            elif scheme == 'mtd_ai':\n",
    "                # try:\n",
    "                #     mtd = mtd_ai_simulation(self.model, self.model_path, start_time, finish_time, total_nodes, new_network = new_network, \n",
    "                #                                              mtd_interval=self.mtd_interval,network_size=self.network_size )  \n",
    "                # except:\n",
    "                #     continue\n",
    "                mtd = mtd_ai_simulation(self.model, self.model_path, start_time, finish_time, total_nodes, new_network = new_network, \n",
    "                                            mtd_interval=self.mtd_interval,network_size=self.network_size )    \n",
    "            else:\n",
    "                mtd = specific_multiple_mtd_simulation(scheme, self.mtd_strategies, scheme, mtd_interval=self.mtd_interval,network_size=self.network_size)\n",
    "        return \n",
    "    \n",
    "    def get_result(self, path, scheme):\n",
    "        csv_path = f'experimental_data/results/{path}.csv'\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return df\n",
    "    \n",
    "    def get_result_checkpoint_median(self, scheme, data, checkpoints = 9):\n",
    "        df = self.get_result(data, scheme).drop('Name', axis = 1)\n",
    "        df['group'] = df.index // checkpoints\n",
    "        # Group by the new column and calculate median\n",
    "        df = df.groupby('group').median().reset_index(drop=True)\n",
    "        # Drop the 'group' column if you don't need it in the result\n",
    "        df = df.drop(columns='group', errors='ignore')\n",
    "        return df\n",
    "\n",
    "    def get_result_stats(self, checkpoint_medians,stats_type = 'median'):\n",
    "        if stats_type == 'median':\n",
    "            return checkpoint_medians.median()\n",
    "        return checkpoint_medians.std()\n",
    "    \n",
    "    def raw_result_stats_pipeline(self, scheme, data, run_trial = False, stats_type = 'median', checkpoints = 9):\n",
    "        if run_trial:\n",
    "            self.run_trials(scheme)\n",
    "        checkpoint_medians = self.get_result_checkpoint_median(scheme, data, checkpoints)\n",
    "        result = self.get_result_stats(checkpoint_medians, stats_type = stats_type)\n",
    "        return result\n",
    "        \n",
    "    def scale_metrics(self, metrics_dict, normalization_dict):\n",
    "        # Define which metrics should be maximized and which should be minimized\n",
    "        metrics_to_maximize = {\"MEF\"}  \n",
    "        metrics_to_minimize = {'host_compromise_ratio', 'time_to_compromise', 'attack_path_exposure', 'ASR', 'ROA', 'exposed_endpoints', \"risk\"}  \n",
    "\n",
    "        scaled_metrics = {}\n",
    "\n",
    "        for key, value in metrics_dict.items():\n",
    "            if key in normalization_dict:\n",
    "                norm_value = normalization_dict[key]\n",
    "\n",
    "                if norm_value != 0:\n",
    "                    if key in metrics_to_maximize:\n",
    "                        # Normalize by dividing the metric value by the normalization value\n",
    "                        scaled_metrics[key] = value / norm_value\n",
    "                    elif key in metrics_to_minimize:\n",
    "                        # Inverse the ratio for metrics to be minimized\n",
    "                        scaled_metrics[key] = 1 / (value / norm_value)\n",
    "                    else:\n",
    "                        # Handle cases where the metric is not in either category\n",
    "                        scaled_metrics[key] = value / norm_value\n",
    "                else:\n",
    "                    # Handle the case where norm_value is zero\n",
    "                    scaled_metrics[key] = 1  # Or any other placeholder value as needed\n",
    "            else:\n",
    "                # Handle cases where normalization value is not defined\n",
    "                scaled_metrics[key] = value  # Or handle differently as needed\n",
    "        return scaled_metrics\n",
    "\n",
    "    def scaled_pipeline(self, scheme, data, run_trial = False, stats_type = 'median'):\n",
    "        nomtd_result = self.raw_result_stats_pipeline('nomtd', 'nomtd', run_trial, stats_type)\n",
    "        scheme_result = self.raw_result_stats_pipeline(scheme, data, run_trial, stats_type)\n",
    "        scaled_scheme_result = self.scale_metrics(scheme_result.to_dict(), nomtd_result.to_dict())\n",
    "        return {scheme:scaled_scheme_result}\n",
    "    \n",
    "    def multiple_scaled_pipeline(self, schemes, data_name, run_trial = False, stats_type = 'median'):\n",
    "        multi_schemes = {}\n",
    "        nomtd_result = self.raw_result_stats_pipeline('nomtd', 'nomtd', run_trial, stats_type)\n",
    "        for scheme, data in zip(schemes, data_name):\n",
    "            scheme_result = self.raw_result_stats_pipeline(scheme, data, run_trial, stats_type)\n",
    "            scaled_scheme_result = self.scale_metrics(scheme_result.to_dict(), nomtd_result.to_dict())\n",
    "\n",
    "            multi_schemes[scheme] = scaled_scheme_result\n",
    "        return multi_schemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "class RadarPlot(Experiment):\n",
    "    def __init__(self, epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network,  model, trial, result_head_path):\n",
    "        super().__init__(epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network,  model, trial, result_head_path)\n",
    "\n",
    "    def plot_n_schemes(self, schemes_data):\n",
    "        \"\"\"\n",
    "        Plots multiple schemes on a radar chart.\n",
    "        \n",
    "        :param schemes_data: A dictionary where keys are scheme names and values are dictionaries of metrics.\n",
    "        \"\"\"\n",
    "        scheme_names = list(schemes_data.keys())\n",
    "        first_scheme = schemes_data[scheme_names[0]]\n",
    "        labels = list(first_scheme.keys())\n",
    "        num_vars = len(labels)\n",
    "\n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "        # Use colormap for colors\n",
    "        colors = plt.cm.tab20.colors\n",
    "        legend_patches = []\n",
    "\n",
    "        for i, scheme_name in enumerate(scheme_names):\n",
    "            metrics_values = schemes_data[scheme_name]\n",
    "            values = list(metrics_values.values())\n",
    "            values += values[:1]  # Close the circle\n",
    "\n",
    "            # Plot data\n",
    "            ax.fill(angles, values, color=colors[i % len(colors)], alpha=0.25)\n",
    "            ax.plot(angles, values, color=colors[i % len(colors)], linewidth=2, label=scheme_name)\n",
    "\n",
    "            # Add score labels\n",
    "            for j in range(num_vars):\n",
    "                angle = angles[j]\n",
    "                value = values[j]\n",
    "                ax.text(angle, value + 0.05, f'{value:.2f}', horizontalalignment='center', size=10, color='black')\n",
    "\n",
    "        # Add labels\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "        # Create legend\n",
    "        legend_patches = [Patch(color=colors[i % len(colors)], label=scheme_name) for i, scheme_name in enumerate(scheme_names)]\n",
    "        plt.legend(handles=legend_patches, loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial_ 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\anaconda3\\envs\\mtdsim\\Lib\\site-packages\\networkx\\drawing\\layout.py:476\u001b[0m, in \u001b[0;36mspring_layout\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(G) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:  \u001b[38;5;66;03m# sparse solver for large graphs\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[0;32m    477\u001b[0m A \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mto_scipy_sparse_array(G, weight\u001b[38;5;241m=\u001b[39mweight, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\Documents\\GitHub\\MTDSim\\mtdnetwork\\operation\\mtd_ai_operation.py:159\u001b[0m, in \u001b[0;36mMTDAIOperation._mtd_execute_action\u001b[1;34m(self, env, mtd, state, time_series, action)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# execute mtd\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m mtd\u001b[38;5;241m.\u001b[39mmtd_operation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_operation\u001b[38;5;241m.\u001b[39mget_adversary())\n\u001b[0;32m    161\u001b[0m finish_time \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnow \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proceed_time\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\Documents\\GitHub\\MTDSim\\mtdnetwork\\mtd\\completetopologyshuffle.py:19\u001b[0m, in \u001b[0;36mCompleteTopologyShuffle.mtd_operation\u001b[1;34m(self, adversary)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Regenerate the network graph\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mgen_graph()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m host_id, host_instance \u001b[38;5;129;01min\u001b[39;00m hosts\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\Documents\\GitHub\\MTDSim\\mtdnetwork\\component\\network.py:184\u001b[0m, in \u001b[0;36mNetwork.gen_graph\u001b[1;34m(self, min_nodes_per_subnet, max_subnets_per_layer, subnet_m_ratio, prob_inter_layer_edge)\u001b[0m\n\u001b[0;32m    182\u001b[0m node_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m s_nodes\n\u001b[1;32m--> 184\u001b[0m subgraph_pos \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mspring_layout(subgraph)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 16:4\u001b[0m, in \u001b[0;36margmap_spring_layout_13\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\anaconda3\\envs\\mtdsim\\Lib\\site-packages\\networkx\\drawing\\layout.py:491\u001b[0m, in \u001b[0;36mspring_layout\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m    490\u001b[0m         k \u001b[38;5;241m=\u001b[39m dom_size \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(nnodes)\n\u001b[1;32m--> 491\u001b[0m     pos \u001b[38;5;241m=\u001b[39m _fruchterman_reingold(\n\u001b[0;32m    492\u001b[0m         A, k, pos_arr, fixed, iterations, threshold, dim, seed\n\u001b[0;32m    493\u001b[0m     )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fixed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 20:4\u001b[0m, in \u001b[0;36margmap__fruchterman_reingold_17\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\anaconda3\\envs\\mtdsim\\Lib\\site-packages\\networkx\\drawing\\layout.py:547\u001b[0m, in \u001b[0;36m_fruchterman_reingold\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# displacement \"force\"\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m displacement \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mijk,ij->ik\u001b[39m\u001b[38;5;124m\"\u001b[39m, delta, (k \u001b[38;5;241m*\u001b[39m k \u001b[38;5;241m/\u001b[39m distance\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m A \u001b[38;5;241m*\u001b[39m distance \u001b[38;5;241m/\u001b[39m k)\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# update positions\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter_set_1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m result \u001b[38;5;241m=\u001b[39m Experiment(epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network, model, trial, result_head_path)\n\u001b[1;32m---> 12\u001b[0m result\u001b[38;5;241m.\u001b[39mrun_trials(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmtd_ai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mExperiment.run_trials\u001b[1;34m(self, scheme)\u001b[0m\n\u001b[0;32m     36\u001b[0m     mtd \u001b[38;5;241m=\u001b[39m single_mtd_simulation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomtd\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m], \n\u001b[0;32m     37\u001b[0m                                              mtd_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtd_interval,network_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_size) \n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmtd_ai\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m#     mtd = mtd_ai_simulation(self.model, self.model_path, start_time, finish_time, total_nodes, new_network = new_network, \u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#                                              mtd_interval=self.mtd_interval,network_size=self.network_size )  \u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# except:\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     mtd \u001b[38;5;241m=\u001b[39m mtd_ai_simulation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path, start_time, finish_time, total_nodes, new_network \u001b[38;5;241m=\u001b[39m new_network, \n\u001b[0;32m     45\u001b[0m                                 mtd_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtd_interval,network_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_size )    \n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     mtd \u001b[38;5;241m=\u001b[39m specific_multiple_mtd_simulation(scheme, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtd_strategies, scheme, mtd_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmtd_interval,network_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_size)\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\Documents\\GitHub\\MTDSim\\experiments\\run.py:202\u001b[0m, in \u001b[0;36mmtd_ai_simulation\u001b[1;34m(file_name, model_path, start_time, finish_time, total_nodes, new_network, mtd_interval, network_size)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mtd_interval \u001b[38;5;129;01min\u001b[39;00m mtd_interval:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m network_size \u001b[38;5;129;01min\u001b[39;00m network_size:\n\u001b[1;32m--> 202\u001b[0m          evaluation \u001b[38;5;241m=\u001b[39m execute_ai_model(\n\u001b[0;32m    203\u001b[0m             start_time\u001b[38;5;241m=\u001b[39mstart_time,\n\u001b[0;32m    204\u001b[0m             finish_time\u001b[38;5;241m=\u001b[39mfinish_time,\n\u001b[0;32m    205\u001b[0m             mtd_interval\u001b[38;5;241m=\u001b[39mmtd_interval,\n\u001b[0;32m    206\u001b[0m             scheme\u001b[38;5;241m=\u001b[39m scheme,\n\u001b[0;32m    207\u001b[0m             total_nodes\u001b[38;5;241m=\u001b[39mtotal_nodes,\n\u001b[0;32m    208\u001b[0m             new_network\u001b[38;5;241m=\u001b[39mnew_network,\n\u001b[0;32m    209\u001b[0m             model_path\u001b[38;5;241m=\u001b[39mmodel_path\n\u001b[0;32m    210\u001b[0m         )\n\u001b[0;32m    211\u001b[0m          evaluation_results \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mevaluation_result_by_compromise_checkpoint(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1.01\u001b[39m, \u001b[38;5;241m0.01\u001b[39m))\n\u001b[0;32m    212\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m evaluation_results:\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\Documents\\GitHub\\MTDSim\\experiments\\run.py:573\u001b[0m, in \u001b[0;36mexecute_ai_model\u001b[1;34m(start_time, finish_time, scheme, mtd_interval, custom_strategies, checkpoints, total_nodes, total_endpoints, total_subnets, total_layers, target_layer, total_database, terminate_compromise_ratio, new_network, epsilon, attacker_sensitivity, model_path)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# start simulation\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finish_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 573\u001b[0m     env\u001b[38;5;241m.\u001b[39mrun(until\u001b[38;5;241m=\u001b[39m(finish_time \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     env\u001b[38;5;241m.\u001b[39mrun(until\u001b[38;5;241m=\u001b[39mend_event)\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\anaconda3\\envs\\mtdsim\\Lib\\site-packages\\simpy\\core.py:254\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StopSimulation \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# == until.value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joo_Kai\\anaconda3\\envs\\mtdsim\\Lib\\site-packages\\simpy\\core.py:206\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(event\u001b[38;5;241m.\u001b[39m_value)(\u001b[38;5;241m*\u001b[39mevent\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    205\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = ['parameter_set_1', 'parameter_set_2', 'parameter_set_3', 'parameter_set_4', 'parameter_set_5', 'parameter_set_6', 'parameter_set_7', 'parameter_set_8', 'parameter_set_9', 'parameter_set_10']\n",
    "for model in models:\n",
    "    print(f\"Running experiments for model {model}\")\n",
    "    result = Experiment(epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network, model, trial, result_head_path)\n",
    "    result.run_trials('mtd_ai')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = 'parameter_set_1'\n",
    "# result = Experiment(epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network, model, trial, result_head_path)\n",
    "# result.run_trials('mtd_ai')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar = RadarPlot(epsilon, start_time, finish_time, mtd_interval, network_size,total_nodes, new_network,  model, trial, result_head_path)\n",
    "schemes_data = radar.multiple_scaled_pipeline(schemes=['mtd_ai', 'random'], data_name=['parameter_set_1', 'random'], run_trial = False)\n",
    "radar.plot_n_schemes(schemes_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtdsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
